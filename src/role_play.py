from src.llm_core import llm_core
from src.summary import save_manager  # ä½¿ç”¨æ–°çš„å­˜æ¡£ç®¡ç†å™¨
import os
import threading
from src import error_handler, summary
from src.error_handler import error_handler
from src.character_generator import generate_character
from src.music_player import MusicPlayer  # ä¿®æ­£å¯¼å…¥
import queue
from rich.console import Console
from rich.panel import Panel
from rich.text import Text
from rich.prompt import Prompt
from rich.markdown import Markdown
from rich.progress import track
from rich import print as rich_print
import re
import toml

# å®šä¹‰éŸ³ä¹æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¯ä»¥ä»ç¯å¢ƒå˜é‡è¯»å–æˆ–è®¾ç½®é»˜è®¤å€¼
MUSIC_FOLDER = "game_music"

# åˆå§‹åŒ–Richæ§åˆ¶å°
console = Console(force_terminal=True)
# åˆå§‹åŒ–éŸ³ä¹æ’­æ”¾å™¨å®ä¾‹
music_player = MusicPlayer()


def format_ai_reply(reply):
    """
    æ ¼å¼åŒ–AIå›å¤ï¼Œä½¿ç”¨Richè¿›è¡Œç¾åŒ–æ˜¾ç¤º
    """
    # åˆ†å‰²å›å¤å†…å®¹
    lines = reply.split('\n')
    formatted_content = []
    current_section = ""
    
    for line in lines:
        original_line = line
        line = line.strip()
        if not line:
            if current_section:
                current_section += "\n"
            continue
            
        # è¯†åˆ«ä¸åŒçš„éƒ¨åˆ†å¹¶åº”ç”¨æ ·å¼
        if line.startswith('ç”¨æˆ·èº«ä»½ï¼š'):
            if current_section:
                formatted_content.append(current_section)
            current_section = f"[bold cyan]ğŸ‘¤ {line}[/bold cyan]"
        elif line.startswith('æ—¶é—´:') or line.startswith('æ—¶é—´ï¼š'):
            current_section += f"\n[yellow]ğŸ• {line}[/yellow]"
        elif line.startswith('åœ°ç‚¹:') or line.startswith('åœ°ç‚¹ï¼š'):
            current_section += f"\n[green]ğŸ“ {line}[/green]"
        elif line.startswith('æƒ…æ™¯:') or line.startswith('æƒ…æ™¯ï¼š'):
            current_section += f"\n[blue]ğŸ¬ {line}[/blue]"
        elif line == '===============':
            current_section += f"\n[dim bright_black]{'â”€' * 50}[/dim bright_black]"
        elif line.startswith('ç”¨æˆ·çŠ¶æ€:') or line.startswith('ç”¨æˆ·çŠ¶æ€ï¼š'):
            current_section += f"\n[magenta]ğŸ’ª {line}[/magenta]"
        elif line.startswith('ç”¨æˆ·ç‰©å“æ :') or line.startswith('ç”¨æˆ·ç‰©å“æ ï¼š'):
            current_section += f"\n[red]ğŸ’ {line}[/red]"
        elif line.startswith('ç”¨æˆ·æ¥ä¸‹æ¥çš„é€‰æ‹©') or line.startswith('é€‰æ‹©'):
            current_section += f"\n[bold yellow]âš¡ {line}[/bold yellow]"
        elif re.match(r'^\d+\.', line):  # æ•°å­—é€‰é¡¹
            current_section += f"\n  [bright_blue]ğŸ”¸ {line}[/bright_blue]"
        elif line.startswith('ğŸµ'):  # éŸ³ä¹ä¿¡æ¯
            current_section += f"\n[bold green]{line}[/bold green]"
        elif line.startswith('ğŸ’¾'):  # ä¿å­˜ä¿¡æ¯
            current_section += f"\n[bold blue]{line}[/bold blue]"
        elif line.startswith('å‰§æƒ…æ‘˜è¦'):
            current_section += f"\n[dim italic]{line}[/dim italic]"
        else:
            # ä¿æŒåŸå§‹çš„ç¼©è¿›å’Œæ ¼å¼
            if original_line.startswith(' ') or original_line.startswith('\t'):
                current_section += f"\n{original_line}"
            else:
                current_section += f"\n[white]{line}[/white]"
    
    if current_section:
        formatted_content.append(current_section)
    
    return "\n\n".join(formatted_content)

def start_role_play(world_description, summary_text, save_name=None, last_conversation=None,role=None):
    if not summary_text and not role:
        role = generate_character(world_description)
        if not role:
            return

    # åˆå§‹è®¾å®š
    def build_system_prompt(include_last_conversation=True):
        prompt = (
            "ä½ æ˜¯ä¸€ä¸ªè§’è‰²è®¾å®šç”Ÿæˆå™¨å’Œè§’è‰²æ‰®æ¼”å¤§å¸ˆã€‚è¯·ä¸¥æ ¼æŒ‰ç…§å¦‚ä¸‹æ ¼å¼è¾“å‡ºæ¯ä¸€è½®å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–å¤šä½™å†…å®¹ï¼š\n"
            "ç”¨æˆ·èº«ä»½ï¼š\n"
            "æ—¶é—´:\n"
            "åœ°ç‚¹:\n"
            "æƒ…æ™¯:\n"
            "===============\n"
            "ç”¨æˆ·çŠ¶æ€:\n"
            "===============\n"
            "ç”¨æˆ·ç‰©å“æ :\n"
            "===============\n"
            "ç”¨æˆ·æ¥ä¸‹æ¥çš„é€‰æ‹©(ä½¿ç”¨æ•°å­—æ ‡è®°):\n"
            "è¯·æ ¹æ®ä»¥ä¸‹ä¸–ç•Œè§‚è¿›è¡Œè§’è‰²æ‰®æ¼”ï¼š\n"
            f"{world_description}\n"
            "ã€æ ¼å¼ç¤ºä¾‹ã€‘\n"
            "ç”¨æˆ·èº«ä»½ï¼šè‰¾ç³Â·æ˜Ÿè¯­\n"
            "æ—¶é—´: æ™¨æ›¦åˆå‡\n"
            "åœ°ç‚¹: é›¾æ—è¾¹å¢ƒ\n"
            "æƒ…æ™¯: ä½ æ­£ç«™åœ¨é›¾æ—è¾¹å¢ƒï¼Œå‡†å¤‡è¸å…¥æœªçŸ¥çš„å†’é™©ã€‚\n"
            "===============\n"
            "ç”¨æˆ·çŠ¶æ€: ç²¾ç¥é¥±æ»¡ï¼Œè£…å¤‡é½å…¨\n"
            "===============\n"
            "ç”¨æˆ·ç‰©å“æ : é­”æ³•çŸ­æ–ï¼Œæ—…è¡Œæ–—ç¯·ï¼Œå¹²ç²®\n"
            "===============\n"
            "ç”¨æˆ·æ¥ä¸‹æ¥çš„é€‰æ‹©(ä½¿ç”¨æ•°å­—æ ‡è®°):\n1. è¿›å…¥é›¾æ— 2. æ£€æŸ¥è£…å¤‡ 3. ä¼‘æ¯ç‰‡åˆ»\n"
            "è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºæ¯ä¸€è½®å†…å®¹ï¼Œä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ–å¤šä½™å†…å®¹ã€‚"
        )
        if summary_text:
            prompt += f"\nå‰§æƒ…æ‘˜è¦ï¼š{summary_text}\n"
            if last_conversation:
                prompt += f"\nä¸Šæ¬¡å¯¹è¯ï¼š{last_conversation.get('content','')}\n,ç›´æ¥è¾“å‡ºä¸Šæ¬¡å¯¹è¯å†…å®¹ï¼Œä¸éœ€è¦é¢å¤–çš„æç¤ºã€‚"
        return prompt

    # åˆå§‹åŒ–å¯¹è¯å†å²
    def get_init_messages(include_last_conversation=True):
        messages = [
            {"role": "system", "content": build_system_prompt(include_last_conversation)}
        ]
        messages.append({"role": "user", "content": f"æˆ‘æ‰®æ¼”ä»¥ä¸‹è§’è‰²ï¼Œè¯·ä»¥è¯¥è§’è‰²çš„èº«ä»½å’Œè§†è§’è¿›è¡Œè§’è‰²æ‰®æ¼”ï¼Œä¸è¦ä»¥æ—è§‚è€…æˆ–å™è¿°è€…è§†è§’ï¼š\n{role}\nè¯·å¼€å§‹è§’è‰²æ‰®æ¼”æ¸¸æˆã€‚"})
        return messages

    # é¦–æ¬¡AIå›å¤ï¼ŒåŒ…å«ä¸Šæ¬¡å¯¹è¯
    messages = get_init_messages(include_last_conversation=True)
    summary_generated = False
    summary_save_name_queue = queue.Queue()  # æ–°å¢é˜Ÿåˆ—ç”¨äºä¼ é€’save_name

    # é¦–æ¬¡å›å¤
    assistant_reply = llm_core.role_play_response(messages, temperature=0.7)
    if assistant_reply is None:
        return
        
    messages.append({"role": "assistant", "content": assistant_reply})
    console.clear()  # ä½¿ç”¨Richæ¸…å±
    
    # ç¾åŒ–æ˜¾ç¤ºAIå›å¤
    formatted_reply = format_ai_reply(assistant_reply)
    console.print(Panel(formatted_reply, title="[bold green]ğŸ­ è§’è‰²æ‰®æ¼”æ¸¸æˆ[/bold green]", border_style="green"))

    # é¦–æ¬¡å›å¤åï¼Œå»é™¤ä¸Šæ¬¡å¯¹è¯å†…å®¹ï¼Œé‡å»º system_prompt
    messages = get_init_messages(include_last_conversation=False)
    messages.append({"role": "user", "content": f"æˆ‘æ‰®æ¼”ä»¥ä¸‹è§’è‰²ï¼š{role}ï¼Œè¯·å¼€å§‹è§’è‰²æ‰®æ¼”æ¸¸æˆ,è¯·ä»¥ä¸–ç•Œè§‚çš„é€»è¾‘ä¸ºä¸»ï¼Œä¸ä»¥æ‰®æ¼”è§’è‰²çš„é€»è¾‘ä¸ºä¸»ã€‚"})
    messages.append({"role": "assistant", "content": assistant_reply})

    turn_count = 0
    mood = None  # åˆå§‹åŒ–éŸ³ä¹åŸºè°ƒå˜é‡
    current_summary = summary_text or ""  # å½“å‰æ‘˜è¦ï¼Œç”¨äºå¢é‡æ›´æ–°
    config = toml.load('config.toml')
    summary_interval = config['game']['summary_interval']  # æ‘˜è¦ç”Ÿæˆçš„è½®æ•°é—´éš”
    summary_save_name_queue = queue.Queue()  # ç”¨äºçº¿ç¨‹é—´ä¼ é€’å®é™…å­˜æ¡£å

    def generate_smart_summary_in_background(messages, world_description, save_name, previous_summary):
        """
        å¢å¼ºå‹æ™ºèƒ½åå°æ‘˜è¦ç”Ÿæˆ - ä½¿ç”¨æ–°çš„æ™ºèƒ½æ‘˜è¦ç³»ç»Ÿ
        """
        nonlocal summary_generated, current_summary
        try:
            # ä½¿ç”¨å¢å¼ºçš„æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ
            if len(messages) > 10:
                # ä¸ºé•¿å¯¹è¯ä½¿ç”¨æ™ºèƒ½æ‘˜è¦ç³»ç»Ÿ
                session_context = f"ä¸–ç•Œè§‚ï¼š{world_description[:200]}ï¼Œè§’è‰²ï¼š{role[:100] if role else 'æœªçŸ¥'}"
                new_summary = llm_core.generate_enhanced_summary(
                    messages=messages,
                    previous_summary=previous_summary,
                    session_context=session_context
                )
            else:
                # è¾ƒçŸ­å¯¹è¯ä½¿ç”¨æ ‡å‡†æ™ºèƒ½æ‘˜è¦
                new_summary = llm_core.generate_smart_summary(
                    messages=messages,
                    previous_summary=previous_summary,
                    enable_optimization=True
                )
            
            if new_summary and new_summary.strip():
                # ç”Ÿæˆä¼˜åŒ–çš„å­˜æ¡£å
                context_info = f"ç¬¬{turn_count}è½®ï¼Œ{mood if mood else 'æœªçŸ¥'}åŸºè°ƒ"
                new_save_name = llm_core.generate_compact_save_name(
                    summary=new_summary,
                    context_info=context_info
                )
                
                # ä½¿ç”¨å­˜æ¡£ç®¡ç†å™¨ä¿å­˜çŠ¶æ€ï¼ˆå·²ç»åŒ…å«äº†æ™ºèƒ½å‹ç¼©ï¼‰
                final_summary, actual_save_name = save_manager.save_game_state(
                    messages=messages,
                    world_description=world_description,
                    save_name=new_save_name,
                    role=role,
                    previous_summary=previous_summary
                )
                
                if final_summary:
                    summary_generated = True
                    current_summary = final_summary  # æ›´æ–°å½“å‰æ‘˜è¦ç”¨äºä¸‹æ¬¡å¢é‡æ›´æ–°
                    # å°†å®é™…ä¿å­˜çš„åç§°æ”¾å…¥é˜Ÿåˆ—
                    summary_save_name_queue.put(actual_save_name or new_save_name)
                    return actual_save_name or new_save_name, final_summary
            
            # ç”Ÿæˆå¤±è´¥æ—¶çš„å›é€€å¤„ç†
            fallback_summary, fallback_name = save_manager.save_game_state(
                messages, world_description, save_name, role, previous_summary
            )
            summary_save_name_queue.put(fallback_name or save_name)
            current_summary = fallback_summary or previous_summary
            return fallback_name or save_name, fallback_summary or previous_summary
            
        except Exception as e:
            # é™é»˜å¤„ç†é”™è¯¯ï¼Œé¿å…æ‰“æ–­ç”¨æˆ·è¾“å…¥
            import logging
            logging.warning(f"ç”Ÿæˆæ™ºèƒ½æ‘˜è¦æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            
            # ä½¿ç”¨æœ€åŸºæœ¬çš„ä¿å­˜æ–¹å¼ä½œä¸ºæœ€åå›é€€
            try:
                backup_summary, backup_name = save_manager.save_game_state(
                    messages, world_description, save_name, role, previous_summary
                )
                summary_save_name_queue.put(backup_name or save_name)
                return backup_name or save_name, backup_summary or previous_summary
            except:
                summary_save_name_queue.put(save_name)
                return save_name, previous_summary

    while True:
        # æ£€æŸ¥æ‘˜è¦çº¿ç¨‹æ˜¯å¦æœ‰æ–°å­˜æ¡£åå’Œæ‘˜è¦æ›´æ–°
        new_save_name = None
        while not summary_save_name_queue.empty():
            new_save_name = summary_save_name_queue.get()
        if new_save_name:
            save_name = new_save_name
            # åŒæ—¶æ›´æ–°å½“å‰æ‘˜è¦ï¼ˆç”¨äºä¸‹æ¬¡å¢é‡æ›´æ–°ï¼‰
            try:
                save_data = save_manager.load_game_state(save_name)
                if save_data[1]:  # å¦‚æœæˆåŠŸåŠ è½½æ‘˜è¦
                    current_summary = save_data[1]
            except:
                pass

        # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        help_text = (
            "ğŸ’¡ [dim]å¯ç”¨å‘½ä»¤: é€€å‡ºã€é‡æ–°å¼€å§‹ã€é‡æ–°ç”Ÿæˆæœ¬å›åˆã€æŸ¥çœ‹æ‘˜è¦[/dim]"
        )
        console.print(help_text)
        console.print()  # ç©ºè¡Œ
        
        user_input = Prompt.ask(
            "[bold yellow]ğŸ® ä½ çš„è¡ŒåŠ¨[/bold yellow]",
            default="",
            show_default=False,
            console=console
        )
        while not user_input.strip():
            console.print("[red]âš ï¸  è¯·è¾“å…¥ä½ çš„è¡ŒåŠ¨ï¼[/red]")
            user_input = Prompt.ask(
                "[bold yellow]ğŸ® ä½ çš„è¡ŒåŠ¨[/bold yellow]",
                default="",
                show_default=False,
                console=console
            )
        if user_input == 'é€€å‡º':
            console.print(Panel(
                "[bold red]ğŸšª æ¸¸æˆå·²é€€å‡ºï¼Œå†è§ï¼[/bold red]",
                title="[red]é€€å‡ºæ¸¸æˆ[/red]",
                border_style="red"
            ))
            break
        elif user_input == 'é‡æ–°å¼€å§‹':
            console.print(Panel(
                "[bold yellow]ğŸ”„ æ­£åœ¨é‡æ–°ç”Ÿæˆåœºæ™¯ï¼Œè¯·ç¨å€™...[/bold yellow]",
                title="[yellow]é‡æ–°å¼€å§‹[/yellow]",
                border_style="yellow"
            ))
            messages = get_init_messages()
            assistant_reply = llm_core.role_play_response(messages, temperature=0.7)
            if assistant_reply:
                messages.append({"role": "assistant", "content": assistant_reply})
                console.clear()
                formatted_reply = format_ai_reply(assistant_reply)
                console.print(Panel(
                    formatted_reply,
                    title="[bold green]ğŸ­ æ–°çš„åœºæ™¯å·²ç”Ÿæˆ[/bold green]",
                    border_style="green"
                ))
            continue
        elif user_input == 'æŸ¥çœ‹æ‘˜è¦':
            if current_summary:
                console.print(Panel(
                    f"[bold cyan]ğŸ“– å½“å‰æ•…äº‹æ‘˜è¦[/bold cyan]\n\n{current_summary}",
                    title="[cyan]æ•…äº‹è¿›åº¦[/cyan]",
                    border_style="cyan"
                ))
            else:
                console.print(Panel(
                    "[yellow]ğŸ“ å½“å‰è¿˜æ²¡æœ‰ç”Ÿæˆæ‘˜è¦ï¼Œè¯·ç»§ç»­æ¸¸æˆå‡ å›åˆåæ‘˜è¦å°†è‡ªåŠ¨ç”Ÿæˆ[/yellow]",
                    title="[yellow]æ‘˜è¦çŠ¶æ€[/yellow]",
                    border_style="yellow"
                ))
            continue
        elif user_input == 'é‡æ–°ç”Ÿæˆæœ¬å›åˆ':
            console.print(Panel(
                "[bold cyan]ğŸ² æ­£åœ¨é‡æ–°ç”Ÿæˆæœ¬å›åˆå†…å®¹ï¼Œè¯·ç¨å€™...[/bold cyan]",
                title="[cyan]é‡æ–°ç”Ÿæˆ[/cyan]",
                border_style="cyan"
            ))
            if len(messages) >= 2 and messages[-1]["role"] == "assistant" and messages[-2]["role"] == "user":
                messages = messages[:-1]  # ç§»é™¤æœ€åä¸€ä¸ªassistantå›å¤
                assistant_reply = llm_core.role_play_response(messages, temperature=0.7)
                if assistant_reply:
                    messages.append({"role": "assistant", "content": assistant_reply})
                    formatted_reply = format_ai_reply(assistant_reply)
                    console.print(Panel(
                        formatted_reply,
                        title="[bold cyan]ğŸ² æœ¬å›åˆå†…å®¹å·²é‡æ–°ç”Ÿæˆ[/bold cyan]",
                        border_style="cyan"
                    ))
            else:
                console.print("[red]âŒ æ— æ³•é‡æ–°ç”Ÿæˆæœ¬å›åˆï¼ˆå†å²è®°å½•ä¸è¶³ï¼‰[/red]")
            continue

        # ç”¨æˆ·è¾“å…¥å†…åµŒåˆ°æç¤ºä¸­ï¼Œå¹¶è¿½åŠ åˆ°å¯¹è¯å†å²
        action_prompt = f"æˆ‘çš„è¡ŒåŠ¨ï¼š{user_input}"
        messages.append({"role": "user", "content": action_prompt})
        assistant_reply = llm_core.role_play_response(messages, temperature=0.7)
        if assistant_reply is None:
            continue

        # æ£€æŸ¥æ‘˜è¦ç”Ÿæˆé˜Ÿåˆ—ï¼Œè‹¥æœ‰æ–°save_nameåˆ™æ·»åŠ åˆ°å›å¤ä¸­
        if not summary_save_name_queue.empty():
            latest_save_name = summary_save_name_queue.get()
            # ä½¿ç”¨æ›´è¯¦ç»†çš„ä¿å­˜å®Œæˆä¿¡æ¯
            assistant_reply += f"\n\nâœ… æ™ºèƒ½å­˜æ¡£å·²å®Œæˆ: {latest_save_name}"
            assistant_reply += f"\nğŸ” å·²ä¼˜åŒ–å¯¹è¯å†…å®¹å¹¶ç”Ÿæˆé«˜è´¨é‡æ‘˜è¦"
            summary_generated = False  # é‡ç½®æ ‡å¿—

        messages.append({"role": "assistant", "content": assistant_reply})

        # æ£€æŸ¥éŸ³ä¹æ’­æ”¾å¼€å…³
        config = toml.load('config.toml')
        enable_music = config['game']['enable_music']

        if enable_music and turn_count == 0:  # ç¬¬é›¶å›åˆè‡ªåŠ¨æ’­æ”¾éŸ³ä¹
            available_moods = [name for name in os.listdir(MUSIC_FOLDER) if os.path.isdir(os.path.join(MUSIC_FOLDER, name))]
            mood = llm_core.select_music_mood(assistant_reply, available_moods)

            # åŠ¨æ€è¯»å–åŸºè°ƒæ–‡ä»¶å¤¹åç§°ï¼Œé™é»˜é‡è¯•
            retry_count = 0
            while mood not in available_moods and retry_count < 3:
                mood = llm_core.select_music_mood(assistant_reply, available_moods)
                retry_count += 1

            if mood and mood in available_moods:
                music_status = music_player.play_music_by_mood(mood)  # ä¿®æ­£ä¸ºå®ä¾‹æ–¹æ³•è°ƒç”¨
                # åªåœ¨AIå›å¤ä¸­æ˜¾ç¤ºéŸ³ä¹ä¿¡æ¯ï¼Œä¸å•ç‹¬æ‰“å°
                assistant_reply += f"\n\nğŸµ {mood}åŸºè°ƒéŸ³ä¹å·²å¼€å§‹æ’­æ”¾"
            else:
                # é™é»˜å¤„ç†ï¼Œä¸æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                pass
        elif enable_music and (turn_count % 3 == 0 or turn_count == 0):  # æ¯ä¸‰å›åˆæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ¢éŸ³ä¹
            should_change = llm_core.should_change_music(assistant_reply, mood)
            
            if should_change:
                # è°ƒç”¨AIç”ŸæˆåŸºè°ƒå¹¶æ’­æ”¾éŸ³ä¹
                available_moods = [name for name in os.listdir(MUSIC_FOLDER) if os.path.isdir(os.path.join(MUSIC_FOLDER, name))]
                new_mood = llm_core.select_music_mood(assistant_reply, available_moods)

                # é™é»˜é‡è¯•ï¼Œé¿å…æ‰“å°é”™è¯¯ä¿¡æ¯
                retry_count = 0
                while new_mood not in available_moods and retry_count < 3:
                    new_mood = llm_core.select_music_mood(assistant_reply, available_moods)
                    retry_count += 1

                if new_mood and new_mood in available_moods:
                    mood = new_mood  # æ›´æ–°å½“å‰åŸºè°ƒ
                    music_status = music_player.play_music_by_mood(mood)  # ä¿®æ­£ä¸ºå®ä¾‹æ–¹æ³•è°ƒç”¨
                    assistant_reply += f"\n\nğŸµ éŸ³ä¹å·²åˆ‡æ¢è‡³{mood}åŸºè°ƒ"
                # å¦‚æœæ— æ³•ç”Ÿæˆæœ‰æ•ˆåŸºè°ƒï¼Œé™é»˜å¤„ç†ï¼Œä¸æ·»åŠ é”™è¯¯ä¿¡æ¯

        # è¾“å‡ºAIå›å¤
        console.clear()  # ä½¿ç”¨Richæ¸…å±
        formatted_reply = format_ai_reply(assistant_reply)
        console.print(Panel(
            formatted_reply,
            title="[bold green]ğŸ­ è§’è‰²æ‰®æ¼”æ¸¸æˆ[/bold green]",
            border_style="green"
        ))

        # æ¯xè½®ç”Ÿæˆä¸€æ¬¡æ™ºèƒ½æ‘˜è¦ï¼Œå¹¶åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œ
        turn_count += 1
        if turn_count % summary_interval == 0:
            # æ˜¾ç¤ºæ™ºèƒ½æ‘˜è¦ç”ŸæˆçŠ¶æ€
            progress_msg = f"\n\nğŸ’¡ ç¬¬{turn_count}è½®ï¼šæ­£åœ¨ç”Ÿæˆæ™ºèƒ½æ‘˜è¦å’Œä¼˜åŒ–å­˜æ¡£..."
            assistant_reply += progress_msg
            
            # é‡æ–°æ˜¾ç¤ºå½“å‰å›å¤ï¼ˆåŒ…å«è¿›åº¦ä¿¡æ¯ï¼‰
            console.clear()
            formatted_reply = format_ai_reply(assistant_reply)
            console.print(Panel(
                formatted_reply,
                title="[bold green]ğŸ­ è§’è‰²æ‰®æ¼”æ¸¸æˆ[/bold green]",
                border_style="green"
            ))
            
            # å¯åŠ¨å¢å¼ºå‹åå°æ‘˜è¦ç”Ÿæˆ
            summary_thread = threading.Thread(
                target=generate_smart_summary_in_background,
                args=(messages, world_description, save_name, current_summary),
                daemon=True  # è®¾ä¸ºå®ˆæŠ¤çº¿ç¨‹ï¼Œä¸»ç¨‹åºé€€å‡ºæ—¶è‡ªåŠ¨ç»“æŸ
            )
            summary_thread.start()
        
        # æ™ºèƒ½æ‘˜è¦ä¼˜åŒ–ï¼šæ¯2è½®è¿›è¡Œä¸€æ¬¡è½»é‡çº§çŠ¶æ€æ›´æ–°
        elif turn_count % 2 == 0 and turn_count > 0:
            # ä½¿ç”¨è½»é‡çº§æ‘˜è¦æ›´æ–°ï¼Œä¸ä¿å­˜æ–‡ä»¶
            try:
                recent_progress = llm_core.generate_smart_summary(
                    messages=messages[-4:],  # åªåˆ†ææœ€è¿‘4æ¡æ¶ˆæ¯
                    previous_summary="",
                    max_tokens=200,
                    enable_optimization=True
                )
                if recent_progress and len(recent_progress.strip()) > 10:
                    # æ›´æ–°å†…å­˜ä¸­çš„å½“å‰æ‘˜è¦
                    if current_summary:
                        # åˆå¹¶æœ€æ–°è¿›å±•åˆ°å½“å‰æ‘˜è¦
                        current_summary = f"{current_summary[:400]}...æœ€æ–°ï¼š{recent_progress[:100]}"
                    else:
                        current_summary = recent_progress
            except:
                pass  # è½»é‡çº§æ›´æ–°å¤±è´¥æ—¶å¿½ç•¥

